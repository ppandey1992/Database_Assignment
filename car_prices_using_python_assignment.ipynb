{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Car Prices \u2013 Pandas Assignment (Jupyter Notebook)\n\n> **Note:** Keep this notebook in the **same folder** as `car_prices.csv` so that the code can read the file directly.\n> The code tries to automatically detect the correct column names (price, brand, year, odometer, etc.)  \n> If your dataset uses slightly different column names, just adjust the `candidate_columns` dictionary once.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Data Ingestion & Quality Profiling"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1.1 Load & Inspect"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Display plots inside the notebook\n%matplotlib inline\n\n# 1.1 \u2013 Read the CSV file\ndf = pd.read_csv(\"car_prices.csv\")\n\nprint(\"First 5 rows:\")\ndisplay(df.head())\n\nprint(\"\\nBasic info:\")\nprint(df.info())\n\nprint(\"\\nTotal number of records:\", len(df))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1.2 Understanding the Data Structure  \n\nWe will also create a small helper that maps the **logical names** we need (price, brand, year, etc.)  \nto the **actual column names** present in your CSV.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "print(\"Shape of the dataset (rows, columns):\", df.shape)\n\nprint(\"\\nColumn names:\")\nprint(df.columns.tolist())\n\nprint(\"\\nData types:\")\nprint(df.dtypes)\n\n# --- Helper: detect important columns automatically ---\ncandidate_columns = {\n    \"price\": [\"sellingprice\", \"selling_price\", \"price\", \"Selling_Price\", \"sellingPrice\"],\n    \"brand\": [\"make\", \"brand\", \"Brand\", \"Make\"],\n    \"model\": [\"model\", \"Model\", \"model_name\", \"Model_Name\"],\n    \"year\": [\"year\", \"model_year\", \"Year\", \"Model_Year\"],\n    \"odometer\": [\"odometer\", \"mileage\", \"Odometer\", \"Mileage\"],\n    \"condition\": [\"condition\", \"Condition\", \"condition_score\", \"Condition_Score\"],\n    \"state\": [\"state\", \"State\", \"state_or_province\"],\n    \"color\": [\"color\", \"Color\", \"exterior_color\", \"Exterior_Color\"],\n    \"interior\": [\"interior\", \"Interior\", \"interior_color\", \"Interior_Color\"],\n}\n\ncol_map = {}\n\nfor logical_name, candidates in candidate_columns.items():\n    for c in candidates:\n        if c in df.columns:\n            col_map[logical_name] = c\n            break\n\nprint(\"\\nDetected column mapping (logical_name -> actual column):\")\nfor k, v in col_map.items():\n    print(f\"{k:10s} -> {v}\")\n\n# Optional: you can manually adjust any incorrect mapping here, e.g.\n# col_map[\"price\"] = \"selling_price\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1.3 Missing & Anomaly Detection"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 1.3.1 \u2013 Quantify nulls per column\nnull_counts = df.isna().sum()\nnull_percent = (null_counts / len(df)) * 100\n\nprint(\"Null values per column:\")\ndisplay(pd.DataFrame({\n    \"null_count\": null_counts,\n    \"null_percent\": null_percent.round(2)\n}))\n\n# Visualize missing values using a simple bar chart\nplt.figure(figsize=(10, 4))\nplt.bar(null_counts.index, null_counts.values)\nplt.xticks(rotation=90)\nplt.ylabel(\"Number of missing values\")\nplt.title(\"Missing values per column\")\nplt.tight_layout()\nplt.show()\n\n# 1.3.2 \u2013 Resolve null values\n# Strategy:\n# - Numeric columns: fill with median\n# - Categorical columns: fill with mode (most frequent)\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\ncategorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n\nfor col in numeric_cols:\n    if df[col].isna().sum() > 0:\n        median_val = df[col].median()\n        df[col].fillna(median_val, inplace=True)\n\nfor col in categorical_cols:\n    if df[col].isna().sum() > 0:\n        mode_val = df[col].mode()[0]\n        df[col].fillna(mode_val, inplace=True)\n\nprint(\"\\nNull values after imputation:\")\nprint(df.isna().sum())\n\n# 1.3.3 \u2013 Duplicates\ndup_count = df.duplicated().sum()\nprint(\"\\nNumber of duplicate records:\", dup_count)\n\nif dup_count > 0:\n    df = df.drop_duplicates().reset_index(drop=True)\n    print(\"Duplicates removed. New shape:\", df.shape)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. DataFrame Queries"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.1 Calculate the average, minimum, and maximum car price"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "price_col = col_map.get(\"price\")\nif price_col is None:\n    raise KeyError(\"Price column not detected. Please set col_map['price'] manually.\")\n\navg_price = df[price_col].mean()\nmin_price = df[price_col].min()\nmax_price = df[price_col].max()\n\nprint(f\"Average price: {avg_price:,.2f}\")\nprint(f\"Minimum price: {min_price:,.2f}\")\nprint(f\"Maximum price: {max_price:,.2f}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.2 List all unique colors of cars"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "color_col = col_map.get(\"color\")\nif color_col is None:\n    print(\"No color column detected. Please set col_map['color'] manually.\")\nelse:\n    unique_colors = df[color_col].dropna().unique()\n    print(\"Unique colors:\")\n    print(unique_colors)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.3 Find the number of unique car brands and car models"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "brand_col = col_map.get(\"brand\")\nmodel_col = col_map.get(\"model\")\n\nif brand_col is None or model_col is None:\n    print(\"Please make sure both 'brand' and 'model' columns are correctly mapped in col_map.\")\nelse:\n    n_brands = df[brand_col].nunique()\n    n_models = df[model_col].nunique()\n\n    print(f\"Number of unique car brands: {n_brands}\")\n    print(f\"Number of unique car models: {n_models}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.4 Find all car information having selling prices greater than $165,000"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if price_col is None:\n    price_col = col_map.get(\"price\")\n\nhigh_price_cars = df[df[price_col] > 165000]\nprint(f\"Total cars with price > 165000: {len(high_price_cars)}\")\ndisplay(high_price_cars.head())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.5 Find the top 5 most frequently sold car models"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if model_col is None:\n    model_col = col_map.get(\"model\")\n\ntop_models = df[model_col].value_counts().head(5)\nprint(\"Top 5 most frequently sold car models:\")\ndisplay(top_models)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.6 What is the average selling price of cars by brand (make)?"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if brand_col is None:\n    brand_col = col_map.get(\"brand\")\n\navg_price_by_brand = df.groupby(brand_col)[price_col].mean().sort_values(ascending=False)\nprint(\"Average selling price by brand (make):\")\ndisplay(avg_price_by_brand)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.7 What is the minimum selling price of cars for each interior?"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "interior_col = col_map.get(\"interior\")\n\nif interior_col is None:\n    print(\"No interior column detected. Please set col_map['interior'] manually if available.\")\nelse:\n    min_price_by_interior = df.groupby(interior_col)[price_col].min().sort_values()\n    print(\"Minimum selling price by interior:\")\n    display(min_price_by_interior)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.8 Find highest odometer reading per year from highest to lowest order"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "year_col = col_map.get(\"year\")\nodo_col = col_map.get(\"odometer\")\n\nif year_col is None or odo_col is None:\n    print(\"Please ensure 'year' and 'odometer' columns are correctly mapped in col_map.\")\nelse:\n    max_odo_per_year = (\n        df.groupby(year_col)[odo_col]\n        .max()\n        .sort_values(ascending=False)\n    )\n    print(\"Highest odometer reading per year (sorted from highest to lowest):\")\n    display(max_odo_per_year)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.9 Create a new column for car age (assuming the current year is 2025)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if year_col is None:\n    year_col = col_map.get(\"year\")\n\nCURRENT_YEAR = 2025\ndf[\"car_age\"] = CURRENT_YEAR - df[year_col]\n\nprint(\"Sample of car_age column:\")\ndisplay(df[[year_col, \"car_age\"]].head())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.10 Find the number of cars having a condition \u2265 48 and odometer > 90,000"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "cond_col = col_map.get(\"condition\")\nodo_col = col_map.get(\"odometer\", odo_col)\n\nif cond_col is None or odo_col is None:\n    print(\"Please ensure 'condition' and 'odometer' columns are correctly mapped in col_map.\")\nelse:\n    mask = (df[cond_col] >= 48) & (df[odo_col] > 90000)\n    count_cars = mask.sum()\n    print(f\"Number of cars with condition >= 48 and odometer > 90000: {count_cars}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.11 Which state consistently has higher car prices for newer cars (year > 2013)?"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "state_col = col_map.get(\"state\")\n\nif state_col is None or year_col is None:\n    print(\"Please ensure 'state' and 'year' columns are correctly mapped in col_map.\")\nelse:\n    newer_cars = df[df[year_col] > 2013]\n    avg_price_by_state_new = (\n        newer_cars.groupby(state_col)[price_col]\n        .mean()\n        .sort_values(ascending=False)\n    )\n    print(\"Average price by state for cars with year > 2013:\")\n    display(avg_price_by_state_new)\n\n    if len(avg_price_by_state_new) > 0:\n        print(\"\\nState with highest average price for newer cars:\",\n              avg_price_by_state_new.index[0])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2.12 For cars with excellent condition (top 20%), which makes have the lowest average price (value for money)?"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if cond_col is None:\n    cond_col = col_map.get(\"condition\")\n\nif brand_col is None:\n    brand_col = col_map.get(\"brand\")\n\nif cond_col is None or brand_col is None:\n    print(\"Please ensure 'condition' and 'brand' columns are correctly mapped in col_map.\")\nelse:\n    threshold = df[cond_col].quantile(0.8)  # top 20%\n    excellent_cars = df[df[cond_col] >= threshold]\n\n    value_for_money = (\n        excellent_cars.groupby(brand_col)[price_col]\n        .mean()\n        .sort_values(ascending=True)\n    )\n\n    print(\"Brands with lowest average price among top 20% condition cars (best value for money):\")\n    display(value_for_money.head(10))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Data Visualization and Insights"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.1 Show the correlation of all numerical features (e.g., selling price, odometer)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Select only numeric columns\nnumeric_df = df.select_dtypes(include=[np.number])\n\nprint(\"Numeric columns used for correlation:\")\nprint(numeric_df.columns.tolist())\n\ncorr_matrix = numeric_df.corr()\n\nplt.figure(figsize=(8, 6))\nplt.imshow(corr_matrix, aspect='auto')\nplt.colorbar(label=\"Correlation\")\nplt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\nplt.yticks(range(len(corr_matrix.index)), corr_matrix.index)\nplt.title(\"Correlation heatmap (numeric features)\")\nplt.tight_layout()\nplt.show()\n\ncorr_matrix\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.2 Plot average selling price by year and explain the pattern"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "avg_price_by_year = df.groupby(year_col)[price_col].mean().reset_index()\n\nplt.figure(figsize=(8, 5))\nplt.bar(avg_price_by_year[year_col], avg_price_by_year[price_col])\nplt.xlabel(\"Year\")\nplt.ylabel(\"Average Selling Price\")\nplt.title(\"Average Selling Price by Year\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\navg_price_by_year\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.3 Plot a graph to show average selling price by odometer"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "plt.figure(figsize=(8, 5))\nplt.scatter(df[odo_col], df[price_col], alpha=0.3)\nplt.xlabel(\"Odometer Reading\")\nplt.ylabel(\"Selling Price\")\nplt.title(\"Selling Price vs Odometer\")\nplt.tight_layout()\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.4 Plot number of cars sold in each state and find the top 3 highest car selling states"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if state_col is None:\n    state_col = col_map.get(\"state\")\n\nif state_col is None:\n    print(\"State column not detected. Please set col_map['state'].\")\nelse:\n    cars_per_state = df[state_col].value_counts()\n\n    plt.figure(figsize=(10, 5))\n    plt.bar(cars_per_state.index, cars_per_state.values)\n    plt.xlabel(\"State\")\n    plt.ylabel(\"Number of cars sold\")\n    plt.title(\"Number of cars sold in each state\")\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    plt.show()\n\n    print(\"Top 3 highest car selling states:\")\n    display(cars_per_state.head(3))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.5 Plot a bar graph of average selling price by condition score ranges of size 5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "cond_col = col_map.get(\"condition\", cond_col)\n\nif cond_col is None:\n    print(\"Condition column not detected. Please set col_map['condition'].\")\nelse:\n    cond_series = df[cond_col]\n    min_c = int(cond_series.min())\n    max_c = int(cond_series.max())\n\n    # Create bins of size 5\n    bins_5 = list(range((min_c // 5) * 5, ((max_c // 5) + 1) * 5 + 1, 5))\n    df[\"condition_bin_5\"] = pd.cut(cond_series, bins=bins_5, include_lowest=True)\n\n    avg_price_by_cond_bin = df.groupby(\"condition_bin_5\")[price_col].mean()\n\n    plt.figure(figsize=(10, 5))\n    plt.bar(avg_price_by_cond_bin.index.astype(str), avg_price_by_cond_bin.values)\n    plt.xlabel(\"Condition score range (size 5)\")\n    plt.ylabel(\"Average selling price\")\n    plt.title(\"Average selling price by condition score ranges of size 5\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    avg_price_by_cond_bin\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.6 Plot a bar graph of number of cars sold by condition ranges of size 10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if cond_col is None:\n    cond_col = col_map.get(\"condition\")\n\nif cond_col is None:\n    print(\"Condition column not detected. Please set col_map['condition'].\")\nelse:\n    cond_series = df[cond_col]\n    min_c = int(cond_series.min())\n    max_c = int(cond_series.max())\n\n    # Create bins of size 10\n    bins_10 = list(range((min_c // 10) * 10, ((max_c // 10) + 1) * 10 + 1, 10))\n    df[\"condition_bin_10\"] = pd.cut(cond_series, bins=bins_10, include_lowest=True)\n\n    count_by_cond_bin = df[\"condition_bin_10\"].value_counts().sort_index()\n\n    plt.figure(figsize=(10, 5))\n    plt.bar(count_by_cond_bin.index.astype(str), count_by_cond_bin.values)\n    plt.xlabel(\"Condition score range (size 10)\")\n    plt.ylabel(\"Number of cars\")\n    plt.title(\"Number of cars sold by condition score ranges of size 10\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    count_by_cond_bin\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.7 Box plot of car selling prices grouped by color (with and without outliers)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "color_col = col_map.get(\"color\", color_col)\n\nif color_col is None:\n    print(\"Color column not detected. Please set col_map['color'].\")\nelse:\n    # Boxplot with all data (including outliers)\n    colors = df[color_col].unique()\n\n    plt.figure(figsize=(12, 6))\n    data = [df[df[color_col] == c][price_col] for c in colors]\n    plt.boxplot(data, labels=colors, showfliers=True)\n    plt.xlabel(\"Color\")\n    plt.ylabel(\"Selling Price\")\n    plt.title(\"Selling price distribution by color (with outliers)\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    # Remove outliers using IQR on price\n    Q1 = df[price_col].quantile(0.25)\n    Q3 = df[price_col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    df_no_outliers = df[(df[price_col] >= lower_bound) & (df[price_col] <= upper_bound)]\n\n    colors_no = df_no_outliers[color_col].unique()\n    plt.figure(figsize=(12, 6))\n    data_no = [df_no_outliers[df_no_outliers[color_col] == c][price_col] for c in colors_no]\n    plt.boxplot(data_no, labels=colors_no, showfliers=False)\n    plt.xlabel(\"Color\")\n    plt.ylabel(\"Selling Price\")\n    plt.title(\"Selling price distribution by color (outliers removed)\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}